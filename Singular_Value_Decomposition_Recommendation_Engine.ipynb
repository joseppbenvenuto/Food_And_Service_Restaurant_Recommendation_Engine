{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition Recommendation Engine\n",
    "\n",
    "### Project Description:\n",
    "\n",
    "The below code seeks to use the yelp reviews data from 2008 - 2019 to build a SVD recommendation engine to recommend Toronto restaurants by all standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import surprise\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100763 entries, 0 to 100762\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   business_name  100763 non-null  object \n",
      " 1   user_id        100763 non-null  object \n",
      " 2   old_text       100763 non-null  object \n",
      " 3   stars          100763 non-null  float64\n",
      " 4   new_text       100763 non-null  object \n",
      " 5   topic          100763 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 4.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>old_text</th>\n",
       "      <th>stars</th>\n",
       "      <th>new_text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Levetto</td>\n",
       "      <td>TZQSUDDcA4ek5gBd6BzcjA</td>\n",
       "      <td>In the heart of Chinatown, I discovered it enr...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>heart chinatown discov enrout kensington marke...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Café La Gaffe</td>\n",
       "      <td>TZQSUDDcA4ek5gBd6BzcjA</td>\n",
       "      <td>One of my Baldwin Village favourites!\\n\\nIt's ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>one baldwin villag favourit well establish wel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niuda Hand-Pulled Noodles</td>\n",
       "      <td>TZQSUDDcA4ek5gBd6BzcjA</td>\n",
       "      <td>Great first experience.\\n\\nMy friend and I wer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>great first experi friend late dinner last wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Light Cafe</td>\n",
       "      <td>TZQSUDDcA4ek5gBd6BzcjA</td>\n",
       "      <td>Lots of new things to try on Baldwin this summ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>lot new thing tri baldwin summer includ new ki...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raijin Ramen</td>\n",
       "      <td>TZQSUDDcA4ek5gBd6BzcjA</td>\n",
       "      <td>With the exponential growth of ramen joints in...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>exponenti growth ramen joint citi one remain o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_name                 user_id  \\\n",
       "0                    Levetto  TZQSUDDcA4ek5gBd6BzcjA   \n",
       "1              Café La Gaffe  TZQSUDDcA4ek5gBd6BzcjA   \n",
       "2  Niuda Hand-Pulled Noodles  TZQSUDDcA4ek5gBd6BzcjA   \n",
       "3                 Light Cafe  TZQSUDDcA4ek5gBd6BzcjA   \n",
       "4               Raijin Ramen  TZQSUDDcA4ek5gBd6BzcjA   \n",
       "\n",
       "                                            old_text  stars  \\\n",
       "0  In the heart of Chinatown, I discovered it enr...    4.0   \n",
       "1  One of my Baldwin Village favourites!\\n\\nIt's ...    5.0   \n",
       "2  Great first experience.\\n\\nMy friend and I wer...    4.0   \n",
       "3  Lots of new things to try on Baldwin this summ...    3.0   \n",
       "4  With the exponential growth of ramen joints in...    4.0   \n",
       "\n",
       "                                            new_text  topic  \n",
       "0  heart chinatown discov enrout kensington marke...      3  \n",
       "1  one baldwin villag favourit well establish wel...      0  \n",
       "2  great first experi friend late dinner last wee...      1  \n",
       "3  lot new thing tri baldwin summer includ new ki...      2  \n",
       "4  exponenti growth ramen joint citi one remain o...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data set\n",
    "data = pd.read_csv('Data/Preprocessed_Reviews_Data.csv')\n",
    "data = data.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# Print data summary\n",
    "print('\\n')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set processed in the topic modeling analysis is imported into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data set\n",
    "reader = surprise.Reader(rating_scale = (1, 5))\n",
    "data = Dataset.load_from_df(data[['user_id', 'business_name', 'stars']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is preprocessed before fitting to the SVD algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rmse average: 0.97\n",
      "rmse standard deviation: 0.01\n",
      "\n",
      "\n",
      "mae average: 0.75\n",
      "mae standard deviation: 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate SVD algorithm via cross validation\n",
    "algo = SVD(n_factors = 200, n_epochs = 200, random_state = 100)\n",
    "cross_val = cross_validate(algo, data, measures = ['RMSE', 'MAE'], cv = 10, verbose = False)\n",
    "values = cross_val.values()\n",
    "values_list = list(values)\n",
    "\n",
    "# RMSE\n",
    "rmse = values_list[0]\n",
    "rmse_avg = round(sum(rmse) / len(rmse),2)\n",
    "rmse_std = round(rmse.std(),2)\n",
    "\n",
    "#MAE\n",
    "mae = values_list[1]\n",
    "mae_avg = round(sum(mae) / len(mae),2)\n",
    "mae_std = round(mae.std(),2)\n",
    "\n",
    "# Print results\n",
    "print('\\n' + 'rmse average: ' + str(rmse_avg) + '\\n' + 'rmse standard deviation: ' + str(rmse_std) + '\\n')\n",
    "print('\\n' + 'mae average: ' + str(mae_avg) + '\\n' + 'mae standard deviation: ' + str(mae_std) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross validation, the SVD algorithm appears to be generating fair results considering the star ratings are in range from 1 - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RMSE: 0.9619\n",
      "0.96\n",
      "MAE:  0.7454\n",
      "0.75\n",
      "\n",
      "\n",
      "(911, 200)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data into an 80/20 split\n",
    "trainset, testset = train_test_split(data, test_size = 0.20, random_state = 100)\n",
    "# Generate SVD Algorithm\n",
    "algo = SVD(n_factors = 200, n_epochs = 200, random_state = 100)\n",
    "# Fit trainset to SVD algorithm\n",
    "algo.fit(trainset)\n",
    "# Generate rating predictions\n",
    "predictions_test = algo.test(testset)\n",
    "\n",
    "# Print test results\n",
    "print('\\n')\n",
    "print(str(round(accuracy.rmse(predictions_test),2)))\n",
    "print(str(round(accuracy.mae(predictions_test),2)))\n",
    "print('\\n')\n",
    "print(str(algo.qi.shape) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for the test set are slight lower than the cross validation results. This is a good sign because the variation between the two are low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle file\n",
    "dump(algo, open('SVD_Model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load algo as pickle file\n",
    "algo = load(open('SVD_Model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommendation function\n",
    "def recommendation (rest1, rating1, rest2, rating2, rest3, rating3):\n",
    "    \n",
    "    # Cosine distance between vectors calculation\n",
    "    def cosine_distance(vector_a = np.array, vector_b = np.array):\n",
    "        return cosine(vector_a, vector_b)\n",
    "    \n",
    "    # Retrieve vectors by restaurant name\n",
    "    def get_vector_by_rest_name(rest_name, trained_model):\n",
    "        rest_row_idx = trained_model.trainset._raw2inner_id_items[rest_name]\n",
    "        return trained_model.qi[rest_row_idx]\n",
    "    \n",
    "    # Get vectors by restaurant name for three restaurants\n",
    "    vector1 = get_vector_by_rest_name(rest1, algo)\n",
    "    score1 = rating1\n",
    "    vector2 = get_vector_by_rest_name(rest2, algo)\n",
    "    score2 = rating2\n",
    "    vector3 = get_vector_by_rest_name(rest3, algo)\n",
    "    score3 = rating3\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    \n",
    "    # Calculate cosine similarity for all three chosen restaurants' vectors against all other restaurant vectors\n",
    "    similarity_table1 = []\n",
    "    for rest_name in algo.trainset._raw2inner_id_items.keys():\n",
    "        rest_vector = get_vector_by_rest_name(rest_name, algo)\n",
    "        similarity_score = cosine_distance(vector1, rest_vector)\n",
    "        similarity_table1.append(((1-similarity_score), rest_name))\n",
    "        \n",
    "    # Convert similarity table into a data frame\n",
    "    rest_rec1 = pd.DataFrame(similarity_table1, columns = ['similarity', 'restaurant name'])\n",
    "    # Sort data set to descending\n",
    "    rest_rec1 = rest_rec1.sort_values('similarity', ascending = False)\n",
    "    # Scale cosine score by duplicates\n",
    "    rest_rec1 = rest_rec1.groupby(by = \"restaurant name\").sum()\n",
    "    # Scale cosine score by rating\n",
    "    rest_rec1['similarity'] = rest_rec1['similarity'] * score1\n",
    "    # Sort data set to descending\n",
    "    rest_rec1 = rest_rec1.sort_values('similarity', ascending = False).reset_index()\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    \n",
    "    # Calculate cosine similarity for all three chosen restaurants' vectors against all other restaurant vectors\n",
    "    similarity_table2 = []\n",
    "    for rest_name in algo.trainset._raw2inner_id_items.keys():\n",
    "        rest_vector = get_vector_by_rest_name(rest_name, algo)\n",
    "        similarity_score = cosine_distance(vector2, rest_vector)\n",
    "        similarity_table2.append(((1-similarity_score) * score2, rest_name))\n",
    "        \n",
    "    # Convert similarity table into a data frame\n",
    "    rest_rec2 = pd.DataFrame(similarity_table2, columns = ['similarity', 'restaurant name'])\n",
    "    # Sort data set to descending\n",
    "    rest_rec2 = rest_rec2.sort_values('similarity', ascending = False)\n",
    "    # Scale cosine score by duplicates\n",
    "    rest_rec2 = rest_rec2.groupby(by = \"restaurant name\").sum()\n",
    "    # Scale cosine score by rating\n",
    "    rest_rec2['similarity'] = rest_rec2['similarity'] * score2\n",
    "    # Sort data set to descending\n",
    "    rest_rec2 = rest_rec2.sort_values('similarity', ascending = False).reset_index()\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    \n",
    "    # Calculate cosine similarity for all three chosen restaurants' vectors against all other restaurant vectors\n",
    "    similarity_table3 = []\n",
    "    for rest_name in algo.trainset._raw2inner_id_items.keys():\n",
    "        rest_vector = get_vector_by_rest_name(rest_name, algo)\n",
    "        similarity_score = cosine_distance(vector3, rest_vector)\n",
    "        similarity_table3.append(((1-similarity_score) * score3, rest_name))\n",
    "    \n",
    "    # Convert similarity table into a data frame\n",
    "    rest_rec3 = pd.DataFrame(similarity_table3, columns = ['similarity', 'restaurant name'])\n",
    "    # Sort data set to descending\n",
    "    rest_rec3 = rest_rec3.sort_values('similarity', ascending = False)\n",
    "    # Scale cosine score by duplicates\n",
    "    rest_rec3 = rest_rec3.groupby(by = \"restaurant name\").sum()\n",
    "    # Scale cosine score by rating\n",
    "    rest_rec3['similarity'] = rest_rec3['similarity'] * score2\n",
    "    # Sort data set to descending\n",
    "    rest_rec3 = rest_rec3.sort_values('similarity', ascending = False).reset_index()\n",
    "    \n",
    "    # Create a list of all data frames\n",
    "    df_list = [rest_rec1, rest_rec2, rest_rec3]\n",
    "    # Concatenate all data frames by axis 0\n",
    "    rest_rec4 = pd.concat(df_list, axis = 0)\n",
    "    # Remove all three chosen restaurants \n",
    "    rest_rec4 = rest_rec4.loc[(rest_rec4['restaurant name'] != rest1) & (rest_rec4['restaurant name'] != rest2) &\n",
    "                              (rest_rec4['restaurant name'] != rest3)].reset_index(drop = True)\n",
    "    # Scale cosine score by duplicates\n",
    "    rest_rec4 = rest_rec4.groupby(by = \"restaurant name\").sum().reset_index()\n",
    "    # Sort values by cosine values in descending order\n",
    "    rest_rec4 = rest_rec4.sort_values('similarity', ascending = False).reset_index(drop = True)\n",
    "    \n",
    "    # Print recommendations\n",
    "    print('\\n')\n",
    "    rest_rec4.info()\n",
    "    return rest_rec4.head(10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cosine distances, three restaurant vectors are chosen to compare to the rest of the restaurant vectors among the the data set.\n",
    "\n",
    "The cosine similarity between the vectors are measured returning a list of restaurant names with attached cosine values similar to the chosen restaurants. \n",
    "\n",
    "Duplicate restaurants' cosine values will be summed returning scaled results.\n",
    "\n",
    "Further the chosen restaurants are scaled from 0 - 5 to represent how much the restaurant is liked and depending on these ratings, the list of restaurant names' values are scaled accordingly. The scaling will return similar restaurants that are liked in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908 entries, 0 to 907\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   restaurant name  908 non-null    object \n",
      " 1   similarity       908 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 14.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant name</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shore Club - Toronto</td>\n",
       "      <td>7.809874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buddha's Vegan Foods</td>\n",
       "      <td>7.175418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Café Pamenar</td>\n",
       "      <td>6.913647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jumbo Empanadas</td>\n",
       "      <td>6.182954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pizzeria Libretto Danforth</td>\n",
       "      <td>6.057171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coco Rice Thai Cuisine</td>\n",
       "      <td>5.838682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kit Kat Italian Bar &amp; Grill</td>\n",
       "      <td>5.684728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bar Fancy</td>\n",
       "      <td>5.430922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sushi Inn</td>\n",
       "      <td>5.190064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Karaikudi</td>\n",
       "      <td>5.176134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               restaurant name  similarity\n",
       "0     The Shore Club - Toronto    7.809874\n",
       "1         Buddha's Vegan Foods    7.175418\n",
       "2                 Café Pamenar    6.913647\n",
       "3              Jumbo Empanadas    6.182954\n",
       "4   Pizzeria Libretto Danforth    6.057171\n",
       "5       Coco Rice Thai Cuisine    5.838682\n",
       "6  Kit Kat Italian Bar & Grill    5.684728\n",
       "7                    Bar Fancy    5.430922\n",
       "8                    Sushi Inn    5.190064\n",
       "9                    Karaikudi    5.176134"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test recommendation engine function\n",
    "recommendation(\"Uncle Tetsu's Japanese Cheesecake\", 5, \n",
    "               \"Kyoto House Japanese Restaurant\", 5, \n",
    "               \"Wheat Sheaf Tavern\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the recommendation function is used and the top 10 restaurant recommendations are returned."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
